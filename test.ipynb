{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gammaln\n",
    "from myfunc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ALL Function Definitions\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the CSV data, preprocesses it by adding month, date, and birthday columns,\n",
    "    and filters data for customers with a specific birthday.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['month'] = pd.to_datetime(df['date']).dt.strftime('%b')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['birthday'] = pd.to_datetime(df['birthday'])\n",
    "    df['spend_rand'] = np.random.uniform(20, 40, size=len(df))\n",
    "\n",
    "\n",
    "    # Filter DataFrame for customers with birthday '1/1/2018'\n",
    "    birthday_filter = pd.Timestamp('2018-01-01')\n",
    "    df_filtered = df[df['birthday'] == birthday_filter]\n",
    "    df_filtered.sort_values(by='date', inplace=True)\n",
    "    return df_filtered\n",
    "\n",
    "def calculate_distinct_customer_count(df):\n",
    "    \"\"\"\n",
    "    Groups data by date and counts distinct customer IDs.\n",
    "    \"\"\"\n",
    "    grouped_df = df.groupby('date').agg({\n",
    "        'cust_id': pd.Series.nunique,  # Count distinct customer IDs\n",
    "        'spend_rand': 'sum'  # Sum the spend for each group\n",
    "    }).reset_index()\n",
    "    grouped_df = grouped_df.rename(columns={\n",
    "        'cust_id': 'distinct_cust_count',\n",
    "        'spend_rand': 'total_spend'\n",
    "    })\n",
    "    grouped_df['date'] = pd.to_datetime(grouped_df['date'])\n",
    "    grouped_df.sort_values(by='date', inplace=True)\n",
    "    return grouped_df\n",
    "\n",
    "def calculate_alive_percentage(df):\n",
    "    \"\"\"\n",
    "    Calculates '%Alive' column for the DataFrame.\n",
    "    \"\"\"\n",
    "    base_value = df.loc[df['cohort'] == 0, 'distinct_cust_count'].iloc[0]\n",
    "    df['%Alive'] = df['distinct_cust_count'] / base_value\n",
    "    return df\n",
    "\n",
    "\n",
    "def e_alive(cohort, gamma, delta):\n",
    "    \"\"\"\n",
    "    E(% Alive) function.\n",
    "    \"\"\"\n",
    "    # Convert cohort to numpy array if it's not already\n",
    "    cohort_array = np.array(cohort) if not isinstance(cohort, np.ndarray) else cohort\n",
    "\n",
    "    # Debugging print statements\n",
    "    #print(\"Shapes and types:\")\n",
    "    #print(\"Cohort:\", cohort_array.shape, type(cohort_array))\n",
    "    #print(\"Gamma:\", gamma, type(gamma))\n",
    "    #print(\"Delta:\", delta, type(delta))\n",
    "\n",
    "    # Perform element-wise operations\n",
    "    gamma_delta_sum = gammaln(gamma + delta)\n",
    "    return np.exp(gammaln(delta + cohort_array) + gamma_delta_sum - gammaln(delta) - gammaln(gamma + delta + cohort_array))\n",
    "\n",
    "\n",
    "def calculate_values(df, gamma, delta):\n",
    "    \"\"\"\n",
    "    Calculates E(% Alive), P(ChurnTime = t), and E(# of Cust) for the DataFrame.\n",
    "    \"\"\"\n",
    "    df['E(% Alive)'] = e_alive(df['cohort'], gamma, delta)\n",
    "    df['P(ChurnTime = t)'] = df['E(% Alive)'].diff().fillna(df['E(% Alive)'].iloc[0])\n",
    "    df['E(# of Cust)'] = df['distinct_cust_count'].iloc[0] * df['E(% Alive)']\n",
    "    return df\n",
    "\n",
    "def sse(params, df):\n",
    "    \"\"\"\n",
    "    SSE function for optimization.\n",
    "    \"\"\"\n",
    "    gamma, delta = params\n",
    "    df_temp = calculate_values(df.copy(), gamma, delta)\n",
    "    return np.sum((df_temp['E(# of Cust)'] - df_temp['distinct_cust_count']) ** 2)\n",
    "\n",
    "def optimize_gamma_delta(df, initial_guess):\n",
    "    \"\"\"\n",
    "    Optimizes gamma and delta values using the SSE function.\n",
    "    \"\"\"\n",
    "    result = minimize(sse, initial_guess, args=(df,), bounds=[(0.00001, None), (0.00001, None)])\n",
    "    return result.x\n",
    "\n",
    "def calculate_e_lifetime_years(df, column='t * P(ChurnTime = t)'):\n",
    "    \"\"\"\n",
    "    Calculates the expected lifetime (E(Lifetime)) in years.\n",
    "    \"\"\"\n",
    "    total = df[column].sum()\n",
    "    e_lifetime_years = total / 12\n",
    "    return  e_lifetime_years\n",
    "\n",
    "def calculate_e_lifetime_years_3mo(df, column='t * P(churnTime = t | Alive @ 3)'):\n",
    "    \"\"\"\n",
    "    Calculates the expected lifetime (E(Lifetime)) in years.\n",
    "    \"\"\"\n",
    "    total = df[column].sum()\n",
    "    e_lifetime_years_3mo = total / 12\n",
    "    return  e_lifetime_years_3mo\n",
    "\n",
    "def calculate_new_column(row):\n",
    "    \"\"\"\n",
    "    Calculates the new column 't * P(ChurnTime = t)' for a given row.\n",
    "    \"\"\"\n",
    "    # Use 'cohort' directly since it's an integer\n",
    "    return row['cohort'] * row['P(ChurnTime = t)']\n",
    "\n",
    "def append_new_row(df):\n",
    "    \"\"\"\n",
    "    Appends a new row to the dataframe with specified calculations.\n",
    "\n",
    "    :param df: The dataframe to which the row will be appended.\n",
    "    :param initial_cust_count: The initial customer count, used for 'E(# of Cust)' calculation.\n",
    "    :return: The dataframe with the new row appended.\n",
    "    \"\"\"\n",
    "    new_row = {\n",
    "        'cohort_month': '> 120',  # as specified\n",
    "        'cohort': 121,  # as specified\n",
    "        't * P(ChurnTime = t)': df['t * P(ChurnTime = t)'].sum(),\n",
    "        # Sum all values for 'P(ChurnTime = t)' to get the new value\n",
    "        'P(ChurnTime = t)': 2 - df['P(ChurnTime = t)'].sum(),\n",
    "        # Calculate the new 'E(% Alive)'\n",
    "        'E(% Alive)': 2 - df['P(ChurnTime = t)'].sum() - df['E(% Alive)'].iloc[-1],\n",
    "        'E(# of Cust)': df['distinct_cust_count'].iloc[0] * (2 - df['P(ChurnTime = t)'].sum() - df['E(% Alive)'].iloc[-1])\n",
    "    }\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_conditional_probability(df):\n",
    "    \"\"\"\n",
    "    Calculates the conditional probability 'P(churnTime = t | Alive @ 3)'.\n",
    "    \"\"\"\n",
    "    # Get the 'E(% Alive)' value for cohort 3\n",
    "    alive_at_3 = df.loc[df['cohort'] == 3, 'E(% Alive)'].values[0]\n",
    "\n",
    "    # Define a function to apply to each row\n",
    "    def calculate_probability(row):\n",
    "        if row['cohort'] <= 3:\n",
    "            return 0\n",
    "        else:\n",
    "            return   row['P(ChurnTime = t)'] / alive_at_3\n",
    "\n",
    "    # Apply the function to each row to create the new column\n",
    "    df['P(churnTime = t | Alive @ 3)'] = df.apply(calculate_probability, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_filtered_sse(df, actual_column, predicted_column):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for non-NaN values in 'distinct_cust_count' and calculates SSE.\n",
    "    \"\"\"\n",
    "    # Filter DataFrame based on non-NaN values in 'distinct_cust_count'\n",
    "    filtered_df = df[df[actual_column].notna()]\n",
    "\n",
    "    # Extract actual and predicted values\n",
    "    actual = filtered_df[actual_column].values\n",
    "    predicted = filtered_df[predicted_column].values\n",
    "\n",
    "    # Calculate SSE\n",
    "    sse = np.sum((actual - predicted) ** 2)\n",
    "\n",
    "    return sse\n",
    "\n",
    "def calculate_t_times_conditional_probability(df, conditional_prob_column='P(churnTime = t | Alive @ 3)', cohort_column='cohort'):\n",
    "    \"\"\"\n",
    "    Calculates the new column 't * P(churnTime = t | Alive @ 3)'.\n",
    "    \n",
    "    :param df: The dataframe containing the data.\n",
    "    :param conditional_prob_column: The name of the column containing 'P(churnTime = t | Alive @ 3)' values.\n",
    "    :param cohort_column: The name of the column containing cohort values.\n",
    "    :return: The dataframe with the new column added.\n",
    "    \"\"\"\n",
    "    # Calculate the new column by multiplying 'P(churnTime = t | Alive @ 3)' by 'cohort'\n",
    "    new_column_name = f\"t * {conditional_prob_column}\"\n",
    "    df[new_column_name] = df[cohort_column] * df[conditional_prob_column]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_financial_metrics(data, margin=0.20, WACC_monthly=0.0095):\n",
    "    \"\"\"\n",
    "    Calculate various financial metrics based on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): Pandas DataFrame containing the data.\n",
    "    margin (float): Margin for calculating profit (default: 20%).\n",
    "    WACC_monthly (float): Monthly Weighted Average Cost of Capital (default: 0.95%).\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Updated DataFrame with new financial metrics.\n",
    "    \"\"\"\n",
    "    data['ARPU'] = data['total_spend'] / data['distinct_cust_count']\n",
    "\n",
    "    # Define the model\n",
    "    def model(params, X):\n",
    "        return params[0] + params[1] * X\n",
    "\n",
    "    # Define the SSE function\n",
    "    def sse(params, X, Y):\n",
    "        return np.sum((Y - model(params, X)) ** 2)\n",
    "\n",
    "    # Extract variables\n",
    "    X = data['cohort']\n",
    "    Y = data['ARPU']\n",
    "\n",
    "    # Initial guess for parameters\n",
    "    initial_guess = [0, 0]\n",
    "\n",
    "    # Optimize parameters\n",
    "    result = minimize(sse, initial_guess, args=(X, Y))\n",
    "    if not result.success:\n",
    "        raise ValueError(result.message)\n",
    "\n",
    "    fitted_params = result.x\n",
    "    b0 = {fitted_params[0]}\n",
    "    b1 = {fitted_params[1]}\n",
    "\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    \n",
    "    data['Calculated_ARPU'] = model(fitted_params, X)\n",
    "    data['E(Total Rev)'] = data['Calculated_ARPU'] * data['distinct_cust_count']\n",
    "    data['E(Rev. per Acq. Cust)'] = data['Calculated_ARPU'] * data['E(% Alive)']\n",
    "    data['E(Profit per Acq. Cust)'] = data['E(Rev. per Acq. Cust)'] * margin\n",
    "    data['PV( E(Profit per Acq. Cust) )'] = data['E(Profit per Acq. Cust)'] / ((1 + WACC_monthly) ** data['cohort'])\n",
    "\n",
    "    return data,b0, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the file\n",
    "# Main Script\n",
    "file_path = \"rich_sample_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusdorne\\AppData\\Local\\Temp\\ipykernel_19024\\2577021119.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.sort_values(by='date', inplace=True)\n",
      "C:\\Users\\gusdorne\\AppData\\Local\\Temp\\ipykernel_19024\\1264120466.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['P(ChurnTime = t)'] = np.abs(df_final['P(ChurnTime = t)'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_month</th>\n",
       "      <th>cohort</th>\n",
       "      <th>distinct_cust_count</th>\n",
       "      <th>%Alive</th>\n",
       "      <th>E(% Alive)</th>\n",
       "      <th>P(ChurnTime = t)</th>\n",
       "      <th>E(# of Cust)</th>\n",
       "      <th>t * P(ChurnTime = t)</th>\n",
       "      <th>P(churnTime = t | Alive @ 3)</th>\n",
       "      <th>t * P(churnTime = t | Alive @ 3)</th>\n",
       "      <th>total_spend</th>\n",
       "      <th>ARPU</th>\n",
       "      <th>Calculated_ARPU</th>\n",
       "      <th>E(Total Rev)</th>\n",
       "      <th>E(Rev. per Acq. Cust)</th>\n",
       "      <th>E(Profit per Acq. Cust)</th>\n",
       "      <th>PV( E(Profit per Acq. Cust) )</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>987.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29543.292828</td>\n",
       "      <td>29.932414</td>\n",
       "      <td>29.804794</td>\n",
       "      <td>29417.331321</td>\n",
       "      <td>29.804794</td>\n",
       "      <td>5.960959</td>\n",
       "      <td>5.960959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.880446</td>\n",
       "      <td>0.849096</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>838.058159</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25700.816139</td>\n",
       "      <td>29.575162</td>\n",
       "      <td>29.835556</td>\n",
       "      <td>25927.097847</td>\n",
       "      <td>25.333263</td>\n",
       "      <td>5.066653</td>\n",
       "      <td>5.018972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.752786</td>\n",
       "      <td>0.746902</td>\n",
       "      <td>0.102194</td>\n",
       "      <td>737.192741</td>\n",
       "      <td>0.204388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21986.084005</td>\n",
       "      <td>29.590961</td>\n",
       "      <td>29.866318</td>\n",
       "      <td>22190.674000</td>\n",
       "      <td>22.307226</td>\n",
       "      <td>4.461445</td>\n",
       "      <td>4.377871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>653.0</td>\n",
       "      <td>0.661601</td>\n",
       "      <td>0.672142</td>\n",
       "      <td>0.074760</td>\n",
       "      <td>663.404149</td>\n",
       "      <td>0.224281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19789.710278</td>\n",
       "      <td>30.305835</td>\n",
       "      <td>29.897080</td>\n",
       "      <td>19522.792997</td>\n",
       "      <td>20.095083</td>\n",
       "      <td>4.019017</td>\n",
       "      <td>3.906617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.600811</td>\n",
       "      <td>0.614559</td>\n",
       "      <td>0.057583</td>\n",
       "      <td>606.569524</td>\n",
       "      <td>0.230333</td>\n",
       "      <td>0.085671</td>\n",
       "      <td>0.342685</td>\n",
       "      <td>17736.798698</td>\n",
       "      <td>29.910284</td>\n",
       "      <td>29.927842</td>\n",
       "      <td>17747.210083</td>\n",
       "      <td>18.392418</td>\n",
       "      <td>3.678484</td>\n",
       "      <td>3.541959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2027-10-01 00:00:00</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>113.289314</td>\n",
       "      <td>0.066903</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.403947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.834154</td>\n",
       "      <td>0.766831</td>\n",
       "      <td>0.253665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2027-11-01 00:00:00</td>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>112.732371</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.099064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.434709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.818819</td>\n",
       "      <td>0.763764</td>\n",
       "      <td>0.250272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2027-12-01 00:00:00</td>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113660</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>112.182710</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.098597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.465471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.803695</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.246935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2028-01-01 00:00:00</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113111</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>111.640178</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.496233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.788780</td>\n",
       "      <td>0.757756</td>\n",
       "      <td>0.243652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>&gt; 120</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.473200</td>\n",
       "      <td>0.168284</td>\n",
       "      <td>20.362341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cohort_month  cohort  distinct_cust_count    %Alive  E(% Alive)  \\\n",
       "0    2018-01-01 00:00:00       0                987.0  1.000000    1.000000   \n",
       "1    2018-02-01 00:00:00       1                869.0  0.880446    0.849096   \n",
       "2    2018-03-01 00:00:00       2                743.0  0.752786    0.746902   \n",
       "3    2018-04-01 00:00:00       3                653.0  0.661601    0.672142   \n",
       "4    2018-05-01 00:00:00       4                593.0  0.600811    0.614559   \n",
       "..                   ...     ...                  ...       ...         ...   \n",
       "117  2027-10-01 00:00:00     117                  NaN       NaN    0.114781   \n",
       "118  2027-11-01 00:00:00     118                  NaN       NaN    0.114217   \n",
       "119  2027-12-01 00:00:00     119                  NaN       NaN    0.113660   \n",
       "120  2028-01-01 00:00:00     120                  NaN       NaN    0.113111   \n",
       "121                > 120     121                  NaN       NaN    0.000000   \n",
       "\n",
       "     P(ChurnTime = t)  E(# of Cust)  t * P(ChurnTime = t)  \\\n",
       "0            1.000000    987.000000              0.000000   \n",
       "1            0.150904    838.058159              0.150904   \n",
       "2            0.102194    737.192741              0.204388   \n",
       "3            0.074760    663.404149              0.224281   \n",
       "4            0.057583    606.569524              0.230333   \n",
       "..                ...           ...                   ...   \n",
       "117          0.000572    113.289314              0.066903   \n",
       "118          0.000564    112.732371              0.066585   \n",
       "119          0.000557    112.182710              0.066271   \n",
       "120          0.000550    111.640178              0.065961   \n",
       "121          0.113111      0.000000             13.473200   \n",
       "\n",
       "     P(churnTime = t | Alive @ 3)  t * P(churnTime = t | Alive @ 3)  \\\n",
       "0                        0.000000                          0.000000   \n",
       "1                        0.000000                          0.000000   \n",
       "2                        0.000000                          0.000000   \n",
       "3                        0.000000                          0.000000   \n",
       "4                        0.085671                          0.342685   \n",
       "..                            ...                               ...   \n",
       "117                      0.000851                          0.099537   \n",
       "118                      0.000840                          0.099064   \n",
       "119                      0.000829                          0.098597   \n",
       "120                      0.000818                          0.098136   \n",
       "121                      0.168284                         20.362341   \n",
       "\n",
       "      total_spend       ARPU  Calculated_ARPU  E(Total Rev)  \\\n",
       "0    29543.292828  29.932414        29.804794  29417.331321   \n",
       "1    25700.816139  29.575162        29.835556  25927.097847   \n",
       "2    21986.084005  29.590961        29.866318  22190.674000   \n",
       "3    19789.710278  30.305835        29.897080  19522.792997   \n",
       "4    17736.798698  29.910284        29.927842  17747.210083   \n",
       "..            ...        ...              ...           ...   \n",
       "117           NaN        NaN        33.403947           NaN   \n",
       "118           NaN        NaN        33.434709           NaN   \n",
       "119           NaN        NaN        33.465471           NaN   \n",
       "120           NaN        NaN        33.496233           NaN   \n",
       "121           NaN        NaN              NaN           NaN   \n",
       "\n",
       "     E(Rev. per Acq. Cust)  E(Profit per Acq. Cust)  \\\n",
       "0                29.804794                 5.960959   \n",
       "1                25.333263                 5.066653   \n",
       "2                22.307226                 4.461445   \n",
       "3                20.095083                 4.019017   \n",
       "4                18.392418                 3.678484   \n",
       "..                     ...                      ...   \n",
       "117               3.834154                 0.766831   \n",
       "118               3.818819                 0.763764   \n",
       "119               3.803695                 0.760739   \n",
       "120               3.788780                 0.757756   \n",
       "121                    NaN                      NaN   \n",
       "\n",
       "     PV( E(Profit per Acq. Cust) )  \n",
       "0                         5.960959  \n",
       "1                         5.018972  \n",
       "2                         4.377871  \n",
       "3                         3.906617  \n",
       "4                         3.541959  \n",
       "..                             ...  \n",
       "117                       0.253665  \n",
       "118                       0.250272  \n",
       "119                       0.246935  \n",
       "120                       0.243652  \n",
       "121                            NaN  \n",
       "\n",
       "[122 rows x 17 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the main calculation to have the final table df_final\n",
    "try:\n",
    "    df_filtered = load_and_preprocess_data(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "\n",
    "grouped_df = calculate_distinct_customer_count(df_filtered)\n",
    "grouped_df['cohort'] = range(len(grouped_df))\n",
    "grouped_df = calculate_alive_percentage(grouped_df)\n",
    "\n",
    "# Optimization\n",
    "initial_guess = [1, 1]\n",
    "optimized_gamma, optimized_delta = optimize_gamma_delta(grouped_df, initial_guess)\n",
    "\n",
    "grouped_df = calculate_values(grouped_df, optimized_gamma, optimized_delta)\n",
    "\n",
    "\n",
    "# Extend the cohort values up to 24 using vectorized operations\n",
    "max_cohort = grouped_df['cohort'].max()\n",
    "extended_cohorts = pd.DataFrame({'cohort': range(max_cohort + 1, 121), '%Alive': np.nan})\n",
    "grouped_df = pd.concat([grouped_df, extended_cohorts], ignore_index=True)\n",
    "\n",
    "# Calculate E(% Alive) for the entire range of cohorts\n",
    "grouped_df['E(% Alive)'] = e_alive(grouped_df['cohort'], optimized_gamma, optimized_delta)\n",
    "\n",
    "# Calculate P(ChurnTime = t) and E(# of Cust)\n",
    "initial_cust_count = grouped_df['distinct_cust_count'].iloc[0]\n",
    "grouped_df['P(ChurnTime = t)'] = grouped_df['E(% Alive)'].diff().fillna(grouped_df['E(% Alive)'].iloc[0])\n",
    "grouped_df['E(# of Cust)'] = initial_cust_count * grouped_df['E(% Alive)']\n",
    "\n",
    "# Adding cohort month\n",
    "from pandas.tseries.offsets import MonthBegin\n",
    "start_month = grouped_df['date'].min()\n",
    "grouped_df['cohort_month'] = grouped_df.apply(lambda row: start_month + MonthBegin(n=int(row['cohort'])), axis=1)\n",
    "\n",
    "updated_sample_data, b0,b1 = calculate_financial_metrics(grouped_df)\n",
    "print(b0)\n",
    "\n",
    "# Final DataFrame\n",
    "df_final = grouped_df[['cohort_month', 'cohort', 'total_spend', 'ARPU','distinct_cust_count', '%Alive', 'E(% Alive)', \n",
    "                       'P(ChurnTime = t)', 'E(# of Cust)','Calculated_ARPU', 'E(Total Rev)', 'E(Rev. per Acq. Cust)',\n",
    "       'E(Profit per Acq. Cust)', 'PV( E(Profit per Acq. Cust) )']]\n",
    "df_final['P(ChurnTime = t)'] = np.abs(df_final['P(ChurnTime = t)'])\n",
    "df_final['t * P(ChurnTime = t)'] = df_final.apply(calculate_new_column, axis=1)\n",
    "df_final = append_new_row(df_final)\n",
    "# Apply the function to df_final\n",
    "df_final = calculate_conditional_probability(df_final)\n",
    "df_final = calculate_t_times_conditional_probability(df_final)\n",
    "df_final = df_final[['cohort_month', 'cohort','distinct_cust_count','%Alive', \n",
    "                     'E(% Alive)', 'P(ChurnTime = t)', 'E(# of Cust)','t * P(ChurnTime = t)',\t'P(churnTime = t | Alive @ 3)','t * P(churnTime = t | Alive @ 3)',\n",
    "                     'total_spend', 'ARPU', 'Calculated_ARPU', 'E(Total Rev)', 'E(Rev. per Acq. Cust)','E(Profit per Acq. Cust)', 'PV( E(Profit per Acq. Cust) )']]\n",
    "df_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2455', '3.2954', '3.0454', 1527.268367392978, 146787.79372692984)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting some important values: Lifetime, Lifetime_3mo, future_Lifetime\n",
    "e_lifetime_years = f\"{calculate_e_lifetime_years(df_final):.4f}\"\n",
    "e_lifetime_years_3mo_v = f\"{calculate_e_lifetime_years_3mo(df_final):.4f}\"\n",
    "\n",
    "cohort_nr =  3  ### USER SET\n",
    "\n",
    "e_future_lifetime_years_3mo = calculate_e_lifetime_years_3mo(df_final) - (cohort_nr/12)\n",
    "e_future_lifetime_years_3mo =  f\"{e_future_lifetime_years_3mo:.4f}\"\n",
    "\n",
    "\n",
    "\n",
    "sse_value_1 = calculate_filtered_sse(df_final, actual_column='distinct_cust_count', predicted_column='E(# of Cust)')\n",
    "sse_value_1 # Customer\n",
    "\n",
    "sse_value_2 = calculate_filtered_sse(df_final, actual_column='total_spend', predicted_column='E(Total Rev)')\n",
    "sse_value_2 # Revenue\n",
    "\n",
    "e_lifetime_years, e_lifetime_years_3mo_v, e_future_lifetime_years_3mo, sse_value_1, sse_value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527.268367392978"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse_value_1 = calculate_filtered_sse(df_final, actual_column='distinct_cust_count', predicted_column='E(# of Cust)')\n",
    "sse_value_1 # Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gusdorne\\Documents\\GitHub\\fuzzy-succotash\\test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusdorne/Documents/GitHub/fuzzy-succotash/test.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m b0, b1\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b0' is not defined"
     ]
    }
   ],
   "source": [
    "b0, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: b_00 = 30.023190855537333, b_01 = 0.0012976780864855872\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "def model(params, X):\n",
    "    b_00, b_01 = params\n",
    "    return b_00 + b_01 * X\n",
    "\n",
    "# Define the SSE (Sum of Squared Errors) function to minimize\n",
    "def sse(params, X, Y):\n",
    "    return np.sum((Y - model(params, X)) ** 2)\n",
    "\n",
    "X = grouped_df['cohort']\n",
    "Y = grouped_df['ARPU']\n",
    "\n",
    "    # Initial guess for parameters\n",
    "initial_guess = [0, 0]\n",
    "result = minimize(sse, initial_guess, args=(X, Y))\n",
    "    # Optimize parameters\n",
    "if result.success:\n",
    "    fitted_params = result.x\n",
    "    print(f\"Optimized parameters: b_00 = {fitted_params[0]}, b_01 = {fitted_params[1]}\")\n",
    "\n",
    "    # Create new column for calculated ARPU\n",
    "    grouped_df['Calculated_ARPU'] = model(fitted_params, X)\n",
    "else:\n",
    "    raise ValueError(result.message)\n",
    "\n",
    "fitted_params = result.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
